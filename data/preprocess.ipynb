{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fader_networks/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/fader_networks/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import shutil\n",
    "import os\n",
    "import subprocess\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from os import rename\n",
    "from glob import glob\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_dir(data_name, attr_name, target_folders, source_folders, use_shuffle = False) :\n",
    "    images = []\n",
    "    image_formats = ['jpg', 'jpeg', 'png']\n",
    "    \n",
    "    def add_images(images, folders, is_target) :\n",
    "        for folder, n in folders :\n",
    "            n_images = 0\n",
    "            folder_path = os.path.join('./raw_data', folder)\n",
    "            for image_format in image_formats :\n",
    "                temp_images = glob('%s/*.%s'%(folder_path, image_format))\n",
    "                temp_images = temp_images if n is None else temp_images[:n]\n",
    "                temp_attr = [is_target]\n",
    "                temp_attr = temp_attr * len(temp_images)                \n",
    "                images += zip(temp_images, temp_attr)\n",
    "                n_images += len(temp_images)\n",
    "            print('%d images added from %s'%(n_images, folder_path))\n",
    "\n",
    "    add_images(images, source_folders, False)\n",
    "    add_images(images, target_folders, True)\n",
    "    \n",
    "    if use_shuffle :\n",
    "        shuffle(images)\n",
    "    \n",
    "    dir_path = os.path.join('./processed_data', data_name)\n",
    "    image_dir_path = os.path.join(dir_path, 'images')\n",
    "    \n",
    "    assert not os.path.exists(dir_path)\n",
    "    subprocess.Popen(\"mkdir %s\" % dir_path, shell=True).wait()\n",
    "    subprocess.Popen(\"mkdir %s\" % image_dir_path, shell=True).wait()\n",
    "    \n",
    "    f = open(\"%s/list_attr_%s.txt\"%(dir_path, data_name), 'w')\n",
    "    f.write('%d\\n%s\\n'%(len(images), attr_name))\n",
    "    \n",
    "    for idx, (path, attr) in enumerate(images):\n",
    "        file_name = '%06i.jpg' % (idx + 1)\n",
    "        data = '%s %d\\n' % (file_name, 1 if attr else -1)\n",
    "        \n",
    "        shutil.copy(path, os.path.join(image_dir_path, file_name))\n",
    "        f.write(data)\n",
    "        \n",
    "    f.close()\n",
    "    \n",
    "    n_images = len(images)\n",
    "    print(\"Copying %d images completed\"%n_images)\n",
    "    return n_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(data_name, n_images):\n",
    "\n",
    "    output_name = '%s_images_%i_%i.pth' % (data_name, IMG_SIZE, IMG_SIZE)\n",
    "    output_path = os.path.join('./processed_data', data_name, output_name)\n",
    "    assert not os.path.isfile(output_path)\n",
    "\n",
    "    print(\"Reading images from %s/ ...\"%(data_name))\n",
    "    \n",
    "    image_dir = os.path.join('./processed_data', data_name, 'images')\n",
    "    \n",
    "    data = np.zeros([n_images, 3, IMG_SIZE, IMG_SIZE], dtype=np.uint8)\n",
    "    for i in range(1, n_images + 1):\n",
    "        if i % 10000 == 0:\n",
    "            print(i)\n",
    "        \n",
    "        image = mpimg.imread(image_dir + '/%06i.jpg' % i)\n",
    "        assert image.shape == (IMG_SIZE, IMG_SIZE, 3)\n",
    "        data[i - 1, ...] = image.transpose((2, 0, 1))\n",
    "\n",
    "    data = torch.from_numpy(data)\n",
    "    assert data.size() == (n_images, 3, IMG_SIZE, IMG_SIZE)\n",
    "\n",
    "    print(\"Saving images to %s ...\" % output_path)\n",
    "#     torch.save(data[:20000].clone(), 'images_%i_%i_20000.pth' % (IMG_SIZE, IMG_SIZE))\n",
    "    torch.save(data, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_attributes(data_name, n_images):\n",
    "\n",
    "    output_name = '%s_attributes.pth' % (data_name)\n",
    "    output_path = os.path.join('./processed_data', data_name, output_name)\n",
    "    assert not os.path.isfile(output_path)\n",
    "    \n",
    "    file_path = os.path.join('./processed_data', data_name, 'list_attr_%s.txt' % (data_name))\n",
    "    attr_lines = [line.rstrip() for line in open(file_path, 'r')]\n",
    "\n",
    "    assert len(attr_lines) == n_images + 2\n",
    "\n",
    "    attr_keys = attr_lines[1].split()\n",
    "    attributes = {k: np.zeros(n_images, dtype=np.bool) for k in attr_keys}\n",
    "    \n",
    "    for i, line in enumerate(attr_lines[2:]):\n",
    "        image_id = i + 1\n",
    "        split = line.split()\n",
    "#         assert len(split) == 41\n",
    "        assert split[0] == ('%06i.jpg' % image_id)\n",
    "        assert all(x in ['-1', '1'] for x in split[1:])\n",
    "        for j, value in enumerate(split[1:]):\n",
    "            attributes[attr_keys[j]][i] = value == '1'\n",
    "\n",
    "    print(\"Saving attributes to %s ...\" % output_path)\n",
    "    torch.save(attributes, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'angelina_celeba_200k'\n",
    "attr = 'is_target'\n",
    "target_folders = [('Angelina_Jolie_128', None)]\n",
    "source_folders = [('img_celeba_aligned_128', None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193390 images added from ./raw_data/img_celeba_aligned_128\n",
      "649 images added from ./raw_data/Angelina_Jolie_128\n",
      "Copying 194039 images completed\n"
     ]
    }
   ],
   "source": [
    "n_images = make_image_dir(data_name, attr, target_folders, source_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images from angelina_celeba_200k/ ...\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "Saving images to ./processed_data/angelina_celeba_200k/angelina_celeba_200k_images_128_128.pth ...\n"
     ]
    }
   ],
   "source": [
    "preprocess_images(data_name, n_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving attributes to ./processed_data/angelina_celeba_200k/angelina_celeba_200k_attributes.pth ...\n"
     ]
    }
   ],
   "source": [
    "preprocess_attributes(data_name, n_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_fader_networks)",
   "language": "python",
   "name": "conda_fader_networks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
